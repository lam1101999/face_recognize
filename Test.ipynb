{"cells":[{"cell_type":"markdown","metadata":{"id":"6xKnO_NXt3fq"},"source":["#Install libary\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15358,"status":"ok","timestamp":1658029925661,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"TtXBp_Qwt74j","outputId":"2636893b-86c3-41f9-e529-2e60be1c66c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.17.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (2.23.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (0.13.0+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (1.21.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (7.1.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (4.1.1)\n","Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (1.12.0+cu113)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.2\n"]}],"source":["# !pip install black[jupyter]\n","!pip install -U tensorflow-addons\n","!pip install facenet-pytorch"]},{"cell_type":"markdown","metadata":{"id":"H6fok1Kvq1oj"},"source":["#Import and Initial Mount Disk"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32504,"status":"ok","timestamp":1658029958159,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"2CpvcU6MnbV6","outputId":"67b77f0c-02b7-4a5c-c159-c310fda60e4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","# Mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/Colab Notebooks/FaceMaskRecognize\"\n","os.chdir(path)\n","\n","import cv2\n","import io\n","import pickle\n","import math\n","from scipy.spatial.distance import cosine\n","from sklearn.preprocessing import normalize\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import torch\n","import torchvision.transforms as transforms\n","from train.Net import InceptionResNetV1\n","from train.FaceNet import FaceNetModel,call_instance_FaceNet_with_custom, call_instance_FaceNet_without_custom, call_instance_FaceNet_with_last_isDense,convert_train_model_to_embedding\n","from train.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue\n","from facenet_pytorch import InceptionResnetV1\n"]},{"cell_type":"markdown","metadata":{"id":"TYCbQnepU7aG"},"source":["#Format Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlOuVvEvU-Up"},"outputs":[],"source":["# !black TensorFlow.ipynb"]},{"cell_type":"markdown","metadata":{"id":"tnw-EkkkUM72"},"source":["# Work with tensorflow"]},{"cell_type":"markdown","metadata":{"id":"keOrBqvbZbpx"},"source":["## Create Constant Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PnDWS57ZZDX"},"outputs":[],"source":["# # Create constant tensor\n","# scalar = tf.constant(value=[23, 31, 3123])\n","# print(scalar)\n","# # Check for the dimension of tensor\n","# print(scalar.ndim)\n","# # Create constant tensor with 2 dimension\n","# matrix = tf.constant([[12, 32], [31, 32], [3123, 1], [1, 4]])\n","# print(matrix)\n","# # Create constant tensor with 3 dimension\n","# matrix = tf.constant([[[12, 32], [31, 32]], [[3123, 1], [1, 4]]])\n","# print(matrix)"]},{"cell_type":"markdown","metadata":{"id":"uM2MMYT1ZeU2"},"source":["##Create Tensor with Variable and check how they work"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsJNfZnEZjf0"},"outputs":[],"source":["# # Create tensor with tf.Variable\n","# changeableTensor = tf.Variable([10, 12])\n","# unchangeableTensor = tf.constant([10, 10])\n","# changeableTensor[0].assign(3)\n","# # unchangeableTensor[0].assign(4) cannot assign like Tensorflow\n","# print(changeableTensor)\n","# print(unchangeableTensor)"]},{"cell_type":"markdown","metadata":{"id":"90qda3HTZmkk"},"source":["##Create Random Tensor with tf.random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sadnjViZoxq"},"outputs":[],"source":["# random1 = tf.random.Generator.from_seed(10)\n","# random1 = random1.normal([3, 3])\n","# random2 = tf.random.Generator.from_seed(10)\n","# random2 = random2.normal([3, 3])\n","# print(random1)\n","# print(random2)\n","# print(\"----------------------Shuffle tensor with random shuffle---------------\")\n","# not_shuffle = tf.constant([[12, 3], [4, 3], [13, 15], [1, 4]])\n","# print(tf.random.shuffle(not_shuffle))\n"]},{"cell_type":"markdown","metadata":{"id":"GY55aVVnvyq-"},"source":["##Another way to create Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AX6KMPZ1v1_P"},"outputs":[],"source":["# #All is 1\n","# tf.ones([4,7])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-ubcGqEwQUq"},"outputs":[],"source":["# #All is zero\n","# tf.zeros([4,8])"]},{"cell_type":"markdown","metadata":{"id":"9uoC0Zzpxwmb"},"source":["##Create tensor with numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9AZ-ZwlxztE"},"outputs":[],"source":["# print(\"--------------------Create tensor from numpy array--------------------------\")\n","# arrayA = np.arange(start=1, stop=13, dtype=int)\n","# matrixFromA = tf.constant(arrayA, shape=(2, 3, 2))\n","# print(matrixFromA)"]},{"cell_type":"markdown","metadata":{"id":"Zgp2XXToz1Uh"},"source":["##Tensor Attribute"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgKYf8Y3z5Y9"},"outputs":[],"source":["# # a Rank 4 tensor\n","# tensor4D = tf.constant(np.arange(start = 1, stop = 73),shape=[3,2,3,4])\n","# print(\"---------------tensor-------------\\n\", tensor4D)\n","# print(\"---------------indexing Tensor-----------\\n\", tensor4D[:,:,0])\n","# print(\"----------------Get shape tensor------------\\n\", tensor4D.shape)\n","# print(\"----------------Dimension------------------\\n\", tensor4D.ndim)\n","# print(\"---------------Size------------\\n\", tf.size(tensor4D).numpy())\n","# print(\"-------------data type------------\\n\", tensor4D.dtype)"]},{"cell_type":"markdown","metadata":{"id":"00I2YKmR6-Nf"},"source":["##Reshape tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRIXXwNJ6_69"},"outputs":[],"source":["# tensor4D = tf.zeros(shape=[3,2,3,4])\n","# tensor2D = tf.reshape(tensor4D, shape = [8,9])\n","# print(tensor2D)"]},{"cell_type":"markdown","metadata":{"id":"0ZRPb4m1Rj3I"},"source":["## Extend tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmaWRiQVR3RA"},"outputs":[],"source":["# tensor2D = tf.zeros(shape = [4,5])\n","# print(\"Original Tensor\\n\", tensor2D)\n","# tensor3D = tf.expand_dims(tensor2D, axis = -1)\n","# print(\"New Tensor\\n\", tensor3D)"]},{"cell_type":"markdown","metadata":{"id":"8LsR_xWSlSyq"},"source":["# Manupilating tensor"]},{"cell_type":"markdown","metadata":{"id":"3MCr0efalZMN"},"source":["## Basic operation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZV_hhJAlW-F"},"outputs":[],"source":["# tensor = tf.constant([[10,4],[12,5]])\n","# # Use build-in operation\n","# print(\"addition\\n\",tensor+10)\n","# print(\"subtraction\\n\",tensor-10)\n","# print(\"multiplication\\n\",tensor*10)\n","# print(\"division\\n\",tensor/10)\n","\n","# # Use function\n","# print(\"________________________________\")\n","# print(\"addition\\n\",tf.add(tensor,10))\n","# print(\"subtraction\\n\",tf.subtract(tensor,10))\n","# print(\"multiplication\\n\",tf.multiply(tensor,10))\n","# print(\"divide\\n\",tf.divide(tensor,10))"]},{"cell_type":"markdown","metadata":{"id":"lvoKuSXFr2lX"},"source":["## Matrix Multiplication"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSCaBI0Lr5Bm"},"outputs":[],"source":["# first_tensor = tf.constant([[10,4,6],\n","#                             [12,5,3],\n","#                             [32,4,1]])\n","# second_tensor = tf.constant([[5,6],\n","#                              [12,5],\n","#                              [5,3]])\n","# print(tf.matmul(first_tensor,second_tensor))"]},{"cell_type":"markdown","metadata":{"id":"u7Bkg28MAx3-"},"source":["# Build train model"]},{"cell_type":"markdown","metadata":{"id":"h7xVYDnAktTn"},"source":["## Init value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_4KeVFgkvqc"},"outputs":[],"source":["# global_value = GlobalValue(image_size=[80,80], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","# format_function = FormatFunction(global_value)"]},{"cell_type":"markdown","metadata":{"id":"X6gRe_BuA1s6"},"source":["## Test Train Model tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szd-zIjl_G2w"},"outputs":[],"source":["# train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n","\n","# # Build your input pipelines\n","# train_dataset = train_dataset.map(format_function.format_gray_image)\n","# train_dataset = train_dataset.shuffle(1024).batch(global_value.BATCH_SIZE)\n","# test_dataset = test_dataset.map(format_function.format_gray_image)\n","# test_dataset = test_dataset.batch(global_value.BATCH_SIZE)\n","\n","# # The embedding model\n","# input_shape = [global_value.IMAGE_SIZE[0], global_value.IMAGE_SIZE[1], 3]\n","# face_net_model = call_instance_FaceNet_with_last_isDense(input_shape,10)\n","\n","\n","# # Compile the model\n","# face_net_model.compile(\n","#     optimizer=tf.keras.optimizers.Adam(0.001),\n","#     loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n","#     )\n","\n","\n","# # Train the network\n","# history = face_net_model.fit(\n","#       train_dataset,\n","#       epochs=global_value.EPOCHS\n","#       )\n","# face_net_model.save(\"save_model/modify_train_mnist\")\n","\n","\n","# # Evaluate the network\n","# results = face_net_model.predict(test_dataset)\n","\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs_48.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta_48.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs_48.tsv')\n","#   files.download('meta_48.tsv')\n","# except:\n","#   pass"]},{"cell_type":"markdown","metadata":{"id":"3ZxjStRYA47o"},"source":["## Save and Load model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbCuEXp79xsa"},"outputs":[],"source":["# # save model\n","# face_net_model.save(\"save_model/number_mnist_48\")\n","# # save loss value\n","# loss_array = history.history['loss']\n","# with open(\"src/loss/mnist_loss.pkl\", 'wb') as file:\n","#     pickle.dump(loss_array, file)\n","\n","# reconstruct_model = tf.keras.models.load_model(\"save_model/modify_train_mnist\")\n","# reconstruct_model = convert_train_model_to_embedding(reconstruct_model)\n","# results = reconstruct_model.predict(test_dataset)\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs_48.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta_48.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs_48.tsv')\n","#   files.download('meta_48.tsv')\n","# except:\n","#   pass"]},{"cell_type":"markdown","metadata":{"id":"ZS12L0cD9xsa"},"source":["## Encoding Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdEkRQ_J9xsa"},"outputs":[],"source":["# train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n","# encoding_dic  = dict()\n","\n","# for i in range (10):\n","#     data_set = train_dataset.filter(lambda image,label: tf.equal(label,i))\n","#     data_set = data_set.map(format_function.format_gray_image)\n","#     data_set = data_set.batch(10)  \n","#     encodes = reconstruct_model.predict(data_set)\n","#     if encodes.any():\n","#         encodes = np.average(encodes, axis=0 )\n","#         encoding_dic[i] = encodes\n","\n","# with open(\"encodings/encoding_train_cross_entropy.pkl\", 'wb') as file:\n","#     pickle.dump(encoding_dic, file)"]},{"cell_type":"markdown","metadata":{"id":"R0dbgCnM9xsb"},"source":["## Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cR3Z8ggmHvvp"},"outputs":[],"source":["# def load_pickle(path):\n","#     with open(path, 'rb') as f:\n","#         encoding_dict = pickle.load(f)\n","#     return encoding_dict\n","\n","# recognition_t=5\n","\n","# def detect(image, encoder,encoding_dict):\n","#     image = tf.expand_dims(image,0)\n","#     encode = encoder(image)\n","#     name = \"unknow\"\n","#     distance = float(\"inf\")\n","#     for db_name, db_encode in encoding_dict.items():\n","#             dist = cosine(db_encode, encode)\n","#             if dist < recognition_t and dist < distance:\n","#                 name = db_name\n","#                 distance = dist\n","\n","#     return name\n","\n","# train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n","# train_dataset = train_dataset.map(format_function.format_gray_image)\n","# test_dataset = test_dataset.map(format_function.format_gray_image)\n","# combined_dataset = train_dataset.concatenate(test_dataset)\n","# combined_dataset = combined_dataset\n","\n","\n","# total = 0\n","# right_choice = 0\n","# i = 0\n","# total_image = len(combined_dataset)\n","# # plt.figure(figsize=(3*(total_image/10), 30))\n","# for image, label in combined_dataset:\n","#     predict_label = detect(image, face_net_model, load_pickle(\"encodings/encoding_train_cross_entropy.pkl\"))\n","#     print(\"predict: {} |||||| actual: {}\".format(predict_label, label))\n","#     # plt.subplot(total_image/10,10,i+1)\n","#     # plt.imshow(image.numpy())\n","#     # plt.title(\"predict: {} |||||| actual: {}\".format(predict_label, label))\n","#     # plt.axis(\"off\")\n","#     total = total + 1\n","#     if(tf.equal(predict_label,label)):\n","#         right_choice = right_choice + 1\n","#     i = i+1\n","# print(total, right_choice)"]},{"cell_type":"markdown","metadata":{"id":"ea45FkJx85vE"},"source":["# Test embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"487FrlI3IChi"},"outputs":[],"source":["# global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","# format_function = FormatFunction(global_value)\n","# # Load network\n","# face_net_model = tf.keras.models.load_model(\"save_model/face_recognize_entropy4\")\n","# face_net_model = convert_train_model_to_embedding(face_net_model)\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/10_person/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_string, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","# # Evaluate the network\n","# results = face_net_model.predict(test_dataset)\n","\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs.tsv')\n","#   files.download('meta.tsv')\n","# except:\n","#   pass"]},{"cell_type":"markdown","source":["# Test embedding pytorch\n"],"metadata":{"id":"4Y5EBEOMGJAK"}},{"cell_type":"code","source":["global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","transform = transforms.ToTensor()\n","# Load network\n","face_net_model = InceptionResnetV1(pretrained='casia-webface').eval()\n","#Preprocess data\n","list_path = file_function.getPath(os.path.join(os.getcwd(), \"dataset\", \"10_person\"))\n","list_label = [x.split(os.path.sep)[-2] for x in list_path]\n","list_image = []\n","for each_path in list_path:\n","  image = format_function.open_and_process_image_Pillow(each_path)\n","  image = transform(image)\n","  image = image.float()\n","  list_image.append(image)\n","list_image_as_tensor = torch.stack(list_image,0)\n","\n","# Evaluate the network\n","results = face_net_model(list_image_as_tensor).detach()\n","results = normalize(results)\n","\n","\n","# Save test embeddings for visualization in projector\n","np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n","\n","out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","for label in list_label:\n","    out_m.write(str(label) + \"\\n\") \n","out_m.close()\n","\n","try:\n","  from google.colab import files\n","  files.download('vecs.tsv')\n","  files.download('meta.tsv')\n","except:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"JQUBZMAoGOrA","executionInfo":{"status":"ok","timestamp":1654071710292,"user_tz":-420,"elapsed":25543,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}},"outputId":"f1f78d29-3dad-4605-b525-5f7d153d8fcf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f2c227ee-2582-448c-bd36-be4fbfd92179\", \"vecs.tsv\", 18706660)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b96d72d0-f75b-4e43-bf64-2692b1cc0636\", \"meta.tsv\", 11464)"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"TH9iO8079PO7"},"source":["#Evaluate"]},{"cell_type":"markdown","source":["##Evaluate no mask lfw"],"metadata":{"id":"MEXqeyIRiyce"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNU388q-C1ii","outputId":"4a436e9a-c932-40b9-9ec9-d3d6db2d93ff","executionInfo":{"status":"ok","timestamp":1656352938740,"user_tz":-420,"elapsed":5623158,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  49\n","11917\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11917/11917 [1:26:55<00:00,  2.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["precision 0.949698229814525, recall 0.9870581496536809, accuracy 0.908869681966938, f1 0.9680178543751531\n"]}],"source":["#Init\n","global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","\n","for i in range(49,50):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model = tf.keras.models.load_model(\"save_model/origin/face_recognize_entropy{}\".format(i))\n","  face_net_model = convert_train_model_to_embedding(face_net_model)\n","  classify = Classify(face_net_model, format_function)\n","\n","  #Get embedding database\n","  # database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  # classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  database_embedding = classify.load_embedding_from_file(os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_align\")\n","  list_path = file_function.getPath(data_directory)\n","  # Accuracy\n","  precision, recall, accuracy,f1 = classify.evaluate_using_confusion_matrix(list_path, database_embedding, 100)\n","  print(\"precision {}, recall {}, accuracy {}, f1 {}\".format(precision, recall, accuracy,f1))"]},{"cell_type":"markdown","source":["## Evaluate mask lfw"],"metadata":{"id":"MAxew-1fi6ho"}},{"cell_type":"code","source":["#Init\n","global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","\n","for i in range(49,50):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model = tf.keras.models.load_model(\"save_model/origin/face_recognize_entropy{}\".format(i))\n","  face_net_model = convert_train_model_to_embedding(face_net_model)\n","  classify = Classify(face_net_model, format_function)\n","\n","  #Get embedding database\n","  # database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  # classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  database_embedding = classify.load_embedding_from_file(os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_mask\")\n","  list_path = file_function.getPath(data_directory)\n","  # Accuracy\n","  precision, recall, accuracy,f1 = classify.evaluate_using_confusion_matrix(list_path, database_embedding, 100)\n","  print(\"precision {}, recall {}, accuracy {}, f1 {}\".format(precision, recall, accuracy,f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnzVIADoirBT","outputId":"89e71455-a789-4da7-d91c-4d53afa0da6a","executionInfo":{"status":"ok","timestamp":1656358336751,"user_tz":-420,"elapsed":5398015,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  49\n","11823\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11823/11823 [1:23:03<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["precision 0.9330562817872555, recall 0.9773543440071706, accuracy 0.8770193690264738, f1 0.9546917274172266\n"]}]},{"cell_type":"markdown","source":["## Evaluate no mask lfw old way"],"metadata":{"id":"gDXu9rgAo5hl"}},{"cell_type":"code","source":["#Init\n","global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","for i in range(49,50):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model = tf.keras.models.load_model(\"save_model/origin/face_recognize_entropy{}\".format(i))\n","  face_net_model = convert_train_model_to_embedding(face_net_model)\n","  classify = Classify(face_net_model, format_function)\n","\n","  #Get embedding database\n","  # database_embedding = classify.embedding_all_data_by_directory_no_normalization(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  # classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test)-old.pkl\".format(i)))\n","  database_embedding = classify.load_embedding_from_file(os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test)-old.pkl\".format(i)))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_align\")\n","  list_path = file_function.getPath(data_directory)\n","\n","  # Accuracy\n","  precision, recall, accuracy,f1 = classify.evaluate_using_confusion_matrix(list_path, database_embedding, 100)\n","  print(\"precision {}, recall {}, accuracy {}, f1 {}\".format(precision, recall, accuracy,f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrVPnHt8-RyT","executionInfo":{"status":"ok","timestamp":1656360242976,"user_tz":-420,"elapsed":1906230,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}},"outputId":"a3b63789-b7df-4fec-a5ec-66fc18c3048b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  49\n","11917\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11917/11917 [31:14<00:00,  6.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["precision 0.9740157358309536, recall 0.9896820096708618, accuracy 0.9268272216161786, f1 0.9817863804104777\n"]}]},{"cell_type":"markdown","source":["## Evaluate mask lfw old way"],"metadata":{"id":"v1xqEHUH_EHI"}},{"cell_type":"code","source":["#Init\n","global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","for i in range(49,50):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model = tf.keras.models.load_model(\"save_model/origin/face_recognize_entropy{}\".format(i))\n","  face_net_model = convert_train_model_to_embedding(face_net_model)\n","  classify = Classify(face_net_model, format_function)\n","\n","  #Get embedding database\n","  # database_embedding = classify.embedding_all_data_by_directory_no_normalization(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  # classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test)-old.pkl\".format(i)))\n","  database_embedding = classify.load_embedding_from_file(os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test)-old.pkl\".format(i)))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_mask\")\n","  list_path = file_function.getPath(data_directory)\n","\n","  # Accuracy\n","  precision, recall, accuracy,f1 = classify.evaluate_using_confusion_matrix(list_path, database_embedding, 100)\n","  print(\"precision {}, recall {}, accuracy {}, f1 {}\".format(precision, recall, accuracy,f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctpbVas9pDeo","executionInfo":{"status":"ok","timestamp":1656362101246,"user_tz":-420,"elapsed":1858276,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}},"outputId":"b9c79235-985d-4bef-9a53-6ea4246e0e11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  49\n","11823\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11823/11823 [30:29<00:00,  6.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["precision 0.9644017666426465, recall 0.9817681497780392, accuracy 0.899264146155798, f1 0.9730074749287803\n"]}]},{"cell_type":"markdown","source":["## Compare time 128 vs 10575"],"metadata":{"id":"WfTUyJoad7an"}},{"cell_type":"code","source":["#Init\n","global_value = GlobalValue(image_size=[110,110], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","\n","for i in range(49,50):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model_10575 = tf.keras.models.load_model(\"save_model/origin/face_recognize_entropy{}\".format(i))\n","  face_net_model_128 = convert_train_model_to_embedding(face_net_model_10575)\n","  #Normalize output \n","  outputs = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(face_net_model_10575.output)\n","  face_net_model_10575 = tf.keras.Model(face_net_model_10575.input, outputs)\n","  \n","  classify_10575 = Classify(face_net_model_10575, format_function)\n","  classify_128 = Classify(face_net_model_128, format_function)\n","\n","\n","\n","  #Get embedding database\n","  database_embedding_10575 = classify_10575.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  database_embedding_128 = classify_128.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_align\")\n","  list_path = file_function.getPath(data_directory)\n","  # Accuracy\n","  right_answer, unknow_answer, mis_answer, total_answer = classify_10575.evaluate(list_path, database_embedding_10575, 100)\n","  print(\"10575 accuracy {}\".format(right_answer/total_answer))\n","  right_answer, unknow_answer, mis_answer, total_answer = classify_128.evaluate(list_path, database_embedding_128, 100)\n","  print(\"128 accuracy {}\".format(right_answer/total_answer))"],"metadata":{"id":"MoqNPdA-d-OP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1878b6a3-8623-47b2-f785-80b33f435e6f","executionInfo":{"status":"ok","timestamp":1657683070210,"user_tz":-420,"elapsed":10167118,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  49\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 5749/5749 [1:38:05<00:00,  1.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["total time 5885.547354221344 for 11917 images, average 0.4938782708921158s per image\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 5749/5749 [06:12<00:00, 15.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total time 372.47496795654297 for 11917 images, average 0.03125576638051045s per image\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11917/11917 [34:31<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["database have 5338 vector, evaluate 11917 image, average_time_encoding 0.06297225824906501, average_time_finding 0.10551678621199764\n","10575 accuracy 0.8988839473021734\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11917/11917 [22:48<00:00,  8.71it/s]"]},{"output_type":"stream","name":"stdout","text":["database have 5338 vector, evaluate 11917 image, average_time_encoding 0.06140715373465706, average_time_finding 0.04825830735685722\n","128 accuracy 0.9278341864563229\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Evaluate inception resnet entropy"],"metadata":{"id":"1MfPmMpMmnqq"}},{"cell_type":"code","source":["#Init\n","model_name = \"Inception-Restnet-Entropy\"\n","global_value = GlobalValue(image_size=[160,160], batch_size = 48, shuffle_size = 512, ratio_train = 0.8, epochs = 40, small_epochs = 2)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()\n","\n","for i in range(27,28):\n","  print(\"evaluate epoch: \", i)\n","  face_net_model = tf.keras.models.load_model(\"save_model/{}/epoch{}\".format(model_name,i))\n","  face_net_model = convert_train_model_to_embedding(face_net_model)\n","  classify = Classify(face_net_model, format_function)\n","\n","  #Get embedding database\n","  database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw_align\"))\n","  # classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  # database_embedding = classify.load_embedding_from_file(os.path.join(os.getcwd(),\"src\",\"encodings\",\"encode_lfw_entropy{}(test).pkl\".format(i)))\n","  #Preprocess data\n","  data_directory = os.path.join(os.getcwd(), \"dataset\", \"lfw_align\")\n","  list_path = file_function.getPath(data_directory)\n","  # Accuracy\n","  precision, recall, accuracy,f1 = classify.evaluate_using_confusion_matrix(list_path, database_embedding, 100)\n","  print(\"precision {}, recall {}, accuracy {}, f1 {}\".format(precision, recall, accuracy,f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Is9_aV-Hmwsj","executionInfo":{"status":"ok","timestamp":1658035575568,"user_tz":-420,"elapsed":5617413,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}},"outputId":"709db8b2-3410-4702-dfe3-f1ef29f466c1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluate epoch:  27\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 5749/5749 [58:58<00:00,  1.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["total time 3538.829464197159 for 11917 images, average 0.2969564038094452s per image\n","11917\n"]},{"output_type":"stream","name":"stderr","text":["100%|**********| 11917/11917 [29:04<00:00,  6.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["precision 0.8714535930491029, recall 0.9421706409034653, accuracy 0.7388604514559033, f1 0.9054334132835303\n"]}]},{"cell_type":"markdown","source":["# Save model weight to use locally"],"metadata":{"id":"P9K2S2ZSi9se"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpN0R7Q3tox8"},"outputs":[],"source":["face_net_model = tf.keras.models.load_model(\"save_model/face_recognize_entropy49\")\n","face_net_model.save_weights(\"model49.h5\")"]},{"cell_type":"code","source":["embedding = dict()\n","with open(\"database.pkl\", 'wb') as file:\n","  pickle.dump(embedding, file)"],"metadata":{"id":"_OQy-AsdAE3Q"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Test.ipynb","provenance":[]},"interpreter":{"hash":"9ca52d78875bca82df506a2a979609a20fc5fdea4089f625e58cd6f5cb8a8554"},"kernelspec":{"display_name":"Python 3.8.12 ('python38')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}