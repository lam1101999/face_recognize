{"cells":[{"cell_type":"markdown","metadata":{"id":"pstlzKwZ2F1l"},"source":["#Import and Initial Mount Disk\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6219,"status":"ok","timestamp":1662511080101,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"cflxDTZEGl_F","outputId":"0849da4d-b448-4e2a-ecb6-4f44f6a1bb10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.7/dist-packages (2.5.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (1.21.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (2.23.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (0.13.1+cu113)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (4.1.1)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (1.12.1+cu113)\n"]}],"source":["# install library\n","!pip install -U tensorflow-addons\n","!pip install facenet-pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6413,"status":"ok","timestamp":1662511086510,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"11TpHNGi2BRj","outputId":"945b5988-6048-4080-a7bf-165365374340"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","# Mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/Colab Notebooks/FaceMaskRecognize\"\n","os.chdir(path)\n","\n","import time\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","from tensorflow.keras import models, layers, metrics, optimizers, Model\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import math\n","import io\n","import pickle\n","import tensorflow_datasets as tfds\n","import random\n","from train.Net import InceptionResNetV1\n","from train.FaceNet import FaceNetModel,call_instance_FaceNet_with_custom, call_instance_FaceNet_without_custom,call_instance_FaceNet_with_last_isDense, convert_train_model_to_embedding\n","from train.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue"]},{"cell_type":"markdown","metadata":{"id":"arWBdNC42LO8"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"cLa5A6udvGwZ"},"source":["## Init value"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1662511086510,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"-EpkTrUkvL8-"},"outputs":[],"source":["READ_RAW_DATA_THEN_SAVE = False\n","MODEL_NAME = \"Inception-Restnet-Entropy-ASIAN\"\n","path_save_model = os.path.join(os.getcwd(), \"save_model\", MODEL_NAME)\n","global_value = GlobalValue(image_size=[160,160], batch_size = 96, shuffle_size = 1000, ratio_train = 0.9, ratio_test = 0.1, ratio_valid = 0.0, epochs = 40, small_epochs = 50,\n","                           image_each_class = 15)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()"]},{"cell_type":"markdown","metadata":{"id":"CNrrqpjynVoz"},"source":["##Prepare folder and other thing"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5pAdqjPenT23","executionInfo":{"status":"ok","timestamp":1662511086510,"user_tz":-420,"elapsed":3,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"outputs":[],"source":["# Create folder to save model\n","if not os.path.exists(path_save_model):\n","  os.makedirs(path_save_model)\n","\n","#Read label dictionary(name of people not the path of image)\n","if READ_RAW_DATA_THEN_SAVE: \n","  label_dict = dict()\n","  label_dict.update(format_function.get_label_dict(os.path.join(os.getcwd(),\"align_image\")))\n","  label_dict.update(format_function.get_label_dict(os.path.join(os.getcwd(),\"dataset\",\"AFDB\")))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","  with open(path, 'wb') as file:\n","    pickle.dump(label_dict, file)\n","path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","with open(path, 'rb') as f:\n","  label_dict = pickle.load(f)\n","\n","#Save data path to file to read faster\n","if READ_RAW_DATA_THEN_SAVE:\n","  path_image_no_mask = list()\n","  path_image_no_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"align_image\")))\n","  path_image_no_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\", \"AFDB\")))\n","  saved_path = os.path.join(os.getcwd(),\"src\",\"data\",\"path_image_no_mask.pkl\")\n","  with open(saved_path, 'wb') as file:\n","      pickle.dump(path_image_no_mask, file)\n","\n","  path_image_mask = list()\n","  path_image_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"face+mask_image\")))\n","  path_image_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\", \"AFDB_mask\")))\n","  saved_path = os.path.join(os.getcwd(),\"src\",\"data\",\"path_image_mask.pkl\")\n","  with open(saved_path, 'wb') as file:\n","      pickle.dump(path_image_mask, file)\n"]},{"cell_type":"markdown","metadata":{"id":"7Dz4PftxE6XC"},"source":["## Start train"]},{"cell_type":"markdown","metadata":{"id":"lZpKIQAUTDpm"},"source":["# Train version 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXpeK2-rTN_n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e27da20a-4e82-437e-ee82-fef55812d5d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["load  /content/drive/MyDrive/Colab Notebooks/FaceMaskRecognize/save_model/Inception-Restnet-Entropy-ASIAN/epoch1\n","--------------------------big epoch 2--------------------------\n","5745/6813 [========================>.....] - ETA: 49:29 - loss: 1.7763 - sparse_categorical_accuracy: 0.7245"]}],"source":["# Create embedding model\n","input_shape = [global_value.IMAGE_SIZE[0], global_value.IMAGE_SIZE[1], 3]\n","face_net_model = call_instance_FaceNet_with_last_isDense(input_shape, len(label_dict))\n","face_net_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n","    )\n","#----Choose path to save per epoch\n","actual_epochs = 1\n","for i in range(100):\n","  last_save_path = path_save_model+\"/epoch{}\".format(actual_epochs)\n","  if not os.path.exists(last_save_path):\n","    break\n","  actual_epochs += 1\n","\n","# Load saved model\n","if (actual_epochs != 1):\n","  load_path = path_save_model+\"/epoch{}\".format(actual_epochs-1)\n","  print(\"load \",load_path)\n","  face_net_model = tf.keras.models.load_model(load_path)\n","\n","\n","\n","# Normal train network\n","for i in range(global_value.EPOCHS):\n","\n","  # Measure time\n","  now = time.time()\n","  # Read data path from file\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"path_image_no_mask.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_no_mask = pickle.load(f)\n","      path_image_no_mask = file_function.get_data_path_with_limit(path_image_no_mask,global_value.IMAGE_EACH_CLASS)\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"path_image_mask.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_mask = pickle.load(f)\n","      path_image_mask = file_function.get_data_path_with_limit(path_image_mask,global_value.IMAGE_EACH_CLASS)\n","\n","  # Combine data path\n","  path_image_no_mask.extend(path_image_mask)\n","  random.shuffle(path_image_no_mask)\n","  # Index label (change label of data from string to number)\n","  label_index =list()\n","  for path in path_image_no_mask:\n","    label = path.split(\"/\")[-2]\n","    label = label_dict[label]\n","    label_index.append(label)\n","  path_dataset = tf.data.Dataset.from_tensor_slices(path_image_no_mask)\n","  label_dataset = tf.data.Dataset.from_tensor_slices(label_index)\n","  origin_dataset = tf.data.Dataset.zip((path_dataset, label_dataset))\n","  # Repeat data\n","  origin_dataset  = origin_dataset.shuffle(global_value.SHUFFLE_SIZE).repeat(2)\n","  # Split train, test datase\n","  train_dataset, test_dataset,_ = format_function.get_dataset_partition(origin_dataset, 0.9,0.1,0)\n","  # read data from path\n","  train_dataset = train_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  # augmentation data(flip, rotate,...)\n","  train_dataset = train_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  test_dataset = test_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","  # batch data\n","  train_dataset = train_dataset.batch(global_value.BATCH_SIZE)\n","  test_dataset = test_dataset.batch(global_value.BATCH_SIZE)\n","  # Set cache and prefetch to improve performance\n","  train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  test_dataset = test_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  print(\"--------------------------big epoch {}--------------------------\".format(actual_epochs))\n","  history = face_net_model.fit(\n","      train_dataset,\n","      epochs = 1,\n","      validation_data = test_dataset\n","  )\n","  face_net_model.save(path_save_model+\"/epoch{}\".format(actual_epochs))\n","  with open(\"src/log/log_{}.txt\".format(MODEL_NAME), \"a\") as file_object:\n","    file_object.write(\"\\n\")\n","    file_object.write(\"epoch {}, loss {}, accuracy {}, loss_valid {}, accuracy_valid {}, time {}\".format(actual_epochs, history.history['loss'], history.history['sparse_categorical_accuracy'], history.history['val_loss'],history.history['val_sparse_categorical_accuracy'], time.time() - now))\n","  actual_epochs += 1\n"]},{"cell_type":"markdown","metadata":{"id":"77wRLLpnwljL"},"source":["## test embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaizwhSWwm9D"},"outputs":[],"source":["# face_net_model = tf.keras.models.load_model(\"save_model/align_image_origin36\")\n","# classify = Classify(face_net_model, format_function)\n","# database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw\"))\n","# classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"encodings\",\"encode_lfw_epoch36.pkl\"))\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/lfw/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","\n","# # Accuracy\n","# print(classify.evaluate(test_dataset, database_embedding))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lT1WdCieksnL"},"outputs":[],"source":["# # Load network\n","# face_net_model = tf.keras.models.load_model(\"save_model/face_recognize_entropy47\")\n","# face_net_model =  convert_train_model_to_embedding(face_net_model)\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/10_person/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","# # Evaluate the network\n","# results = face_net_model.predict(test_dataset)\n","\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs.tsv')\n","#   files.download('meta.tsv')\n","# except:\n","#   pass"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}