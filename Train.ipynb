{"cells":[{"cell_type":"markdown","metadata":{"id":"pstlzKwZ2F1l"},"source":["#Import and Initial Mount Disk\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7207,"status":"ok","timestamp":1665024185046,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"cflxDTZEGl_F","outputId":"b638e6c9-675c-4bea-c3ff-759f6a74227d"},"outputs":[],"source":["# # install library\n","# !pip install -U tensorflow-addons\n","# !pip install facenet-pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2734,"status":"ok","timestamp":1665024187763,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"11TpHNGi2BRj","outputId":"4a99c6af-206d-4bc1-dae9-480077e78eba"},"outputs":[],"source":["import os\n","# # Mount drive\n","# from google.colab import drive\n","# drive.mount(\"/content/drive\")\n","# path = \"/content/drive/My Drive/Colab Notebooks/FaceMaskRecognize\"\n","# os.chdir(path)\n","\n","import time\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","from tensorflow.keras import models, layers, metrics, optimizers, Model\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import math\n","import io\n","import pickle\n","import tensorflow_datasets as tfds\n","import random\n","import csv\n","\n","from train_tensorflow.Net import InceptionResNetV1\n","from train_tensorflow.FaceNet import call_instance_FaceNet_with_last_isDense, convert_train_model_to_embedding, call_instance_FaceNet_ArcFace\n","from train_tensorflow.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue\n","\n"]},{"cell_type":"markdown","metadata":{"id":"arWBdNC42LO8"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"cLa5A6udvGwZ"},"source":["## Init value"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665024187764,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"-EpkTrUkvL8-"},"outputs":[],"source":["READ_RAW_DATA_THEN_SAVE = True\n","MODEL_NAME = \"110-ASIAN\"\n","path_save_model = os.path.join(os.getcwd(), \"save_model\", MODEL_NAME)\n","global_value = GlobalValue(image_size=[110,110], batch_size = 96, shuffle_size = 1000, ratio_train = 0.9, ratio_test = 0.1, ratio_valid = 0.0, epochs = 40, small_epochs = 50,\n","                           image_each_class = 15)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()"]},{"cell_type":"markdown","metadata":{"id":"CNrrqpjynVoz"},"source":["## Prepare folder and other thing"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":32207,"status":"ok","timestamp":1665024219960,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"5pAdqjPenT23"},"outputs":[],"source":["# Create folder to save model\n","if not os.path.exists(path_save_model):\n","  os.makedirs(path_save_model)\n","\n","#Read label dictionary(name of people not the path of image)\n","if READ_RAW_DATA_THEN_SAVE: \n","  label_dict = dict()\n","  label_dict.update(format_function.get_label_dict(os.path.join(os.getcwd(),\"dataset\",\"CASIA_align\")))\n","  label_dict.update(format_function.get_label_dict(os.path.join(os.getcwd(),\"dataset\",\"AFDB\")))\n","  path = os.path.join(os.getcwd(),\"cache\",\"data\",\"label_dict.pkl\")\n","  with open(path, 'wb') as file:\n","    pickle.dump(label_dict, file)\n","path = os.path.join(os.getcwd(),\"cache\",\"data\",\"label_dict.pkl\")\n","with open(path, 'rb') as f:\n","  label_dict = pickle.load(f)\n","\n","#Save data path to file to read faster\n","if READ_RAW_DATA_THEN_SAVE:\n","  path_image_no_mask = list()\n","  path_image_no_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\",\"CASIA_align\")))\n","  path_image_no_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\", \"AFDB\")))\n","  saved_path = os.path.join(os.getcwd(),\"cache\",\"data\",\"path_image_no_mask.pkl\")\n","  with open(saved_path, 'wb') as file:\n","      pickle.dump(path_image_no_mask, file)\n","\n","  path_image_mask = list()\n","  path_image_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\",\"CASIA_mask\")))\n","  path_image_mask.extend(file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"dataset\", \"AFDB_mask\")))\n","  saved_path = os.path.join(os.getcwd(),\"cache\",\"data\",\"path_image_mask.pkl\")\n","  with open(saved_path, 'wb') as file:\n","      pickle.dump(path_image_mask, file)\n"]},{"cell_type":"markdown","metadata":{"id":"7Dz4PftxE6XC"},"source":["## Start train"]},{"cell_type":"markdown","metadata":{"id":"lZpKIQAUTDpm"},"source":["# Train version 2\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QXpeK2-rTN_n"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------big epoch 1--------------------------\n","6591/6591 [==============================] - 4312s 651ms/step - loss: 9.2466 - sparse_categorical_accuracy: 2.4340e-04 - val_loss: 9.0756 - val_sparse_categorical_accuracy: 3.1294e-04\n","--------------------------big epoch 2--------------------------\n","5906/6591 [=========================>....] - ETA: 8:03 - loss: 8.6169 - sparse_categorical_accuracy: 0.0011"]}],"source":["# Create embedding model\n","input_shape = [global_value.IMAGE_SIZE[0], global_value.IMAGE_SIZE[1], 3]\n","face_net_model = call_instance_FaceNet_with_last_isDense(input_shape, len(label_dict))\n","\n","#----Choose path to save per epoch\n","actual_epochs = 1\n","for i in range(1000):\n","  last_save_path = os.path.join(path_save_model,\"epoch{}.h5\".format(actual_epochs))\n","  if not os.path.exists(last_save_path):\n","    break\n","  actual_epochs += 1\n","\n","# Load saved model\n","if (actual_epochs != 1):\n","  load_path = os.path.join(path_save_model,\"epoch{}.h5\".format(actual_epochs-1))\n","  print(\"load \",load_path)\n","  face_net_model.load_weights(load_path)\n","\n","face_net_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",")\n","# Normal train network\n","for i in range(global_value.EPOCHS):\n","\n","  # Measure time\n","  now = time.time()\n","  # Read data path from file\n","  path = os.path.join(os.getcwd(),\"cache\",\"data\",\"path_image_no_mask.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_no_mask = pickle.load(f)\n","      path_image_no_mask = file_function.get_data_path_with_limit(path_image_no_mask,global_value.IMAGE_EACH_CLASS)\n","  path = os.path.join(os.getcwd(),\"cache\",\"data\",\"path_image_mask.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_mask = pickle.load(f)\n","      path_image_mask = file_function.get_data_path_with_limit(path_image_mask,global_value.IMAGE_EACH_CLASS)\n","\n","  # Combine data path\n","  path_image_no_mask.extend(path_image_mask)\n","  random.shuffle(path_image_no_mask)\n","  # Index label (change label of data from string to number)\n","  label_index = list()\n","  for path in path_image_no_mask:\n","    label = path.split(os.sep)[-2]\n","    label = label_dict[label]\n","    label_index.append(label)\n","  path_dataset = tf.data.Dataset.from_tensor_slices(path_image_no_mask)\n","  label_dataset = tf.data.Dataset.from_tensor_slices(label_index)\n","  origin_dataset = tf.data.Dataset.zip((path_dataset, label_dataset))\n","\n","  # Repeat data\n","  origin_dataset  = origin_dataset.shuffle(global_value.SHUFFLE_SIZE).repeat(2)\n","\n","  # Split train, test datase\n","  train_dataset, test_dataset,_ = format_function.get_dataset_partition(origin_dataset, 0.9,0.1,0)\n","  \n","  \n","  # read data from path\n","  train_dataset = train_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  # train_dataset = train_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","  test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  # test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","  \n","  # augmentation data(flip, rotate,...)\n","  train_dataset = train_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  test_dataset = test_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  \n","  # batch data\n","  train_dataset = train_dataset.batch(global_value.BATCH_SIZE)\n","  test_dataset = test_dataset.batch(global_value.BATCH_SIZE)\n","  \n","  \n","  # Set cache and prefetch to improve performance\n","  train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  test_dataset = test_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  \n","  \n","  print(\"--------------------------big epoch {}--------------------------\".format(actual_epochs))\n","  history = face_net_model.fit(\n","      x = train_dataset,\n","      epochs = 1,\n","      validation_data = test_dataset\n","  )\n","  face_net_model.save_weights(os.path.join(path_save_model,\"epoch{}.h5\".format(actual_epochs)))\n","  with open(os.path.join(os.getcwd(),\"cache\",\"log\",MODEL_NAME+\".csv\"), \"a\") as f:\n","    row = [actual_epochs, history.history['loss'], history.history['sparse_categorical_accuracy'], history.history['val_loss'],history.history['val_sparse_categorical_accuracy'], time.time() - now]\n","    writer = csv.writer(f)\n","    writer.writerow(row)\n","  actual_epochs += 1"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('python38')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"725bcb009e1db82e62e6d35a4d1f684f39d1b4e52d6204abc611d06a7adc7e09"}}},"nbformat":4,"nbformat_minor":0}
