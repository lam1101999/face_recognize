{"cells":[{"cell_type":"markdown","metadata":{"id":"pstlzKwZ2F1l"},"source":["#Import and Initial Mount Disk\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6269,"status":"ok","timestamp":1656282928635,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"cflxDTZEGl_F","outputId":"659ba3c6-6f54-4fd0-b871-f33f8cd3580e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.7/dist-packages (2.5.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (0.12.0+cu113)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (3.0.4)\n","Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (4.1.1)\n"]}],"source":["# install library\n","!pip install -U tensorflow-addons\n","!pip install facenet-pytorch"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2396,"status":"ok","timestamp":1656282931024,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"11TpHNGi2BRj","outputId":"1fabea10-4cbc-4342-d45e-75efa561ead5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","# Mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/Colab Notebooks/FaceMaskRecognize\"\n","os.chdir(path)\n","\n","import time\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","from tensorflow.keras import models, layers, metrics, optimizers, Model\n","from functools import partial\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import math\n","import io\n","import pickle\n","import tensorflow_datasets as tfds\n","import random\n","from train.Net import InceptionResNetV1\n","from train.FaceNet import FaceNetModel,call_instance_FaceNet_with_custom, call_instance_FaceNet_without_custom,call_instance_FaceNet_with_last_isDense, convert_train_model_to_embedding\n","from train.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue"]},{"cell_type":"markdown","metadata":{"id":"arWBdNC42LO8"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"cLa5A6udvGwZ"},"source":["## Init value"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"-EpkTrUkvL8-","executionInfo":{"status":"ok","timestamp":1656282931024,"user_tz":-420,"elapsed":5,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"outputs":[],"source":["READ_RAW_DATA_THEN_SAVE = False\n","MODEL_NAME = \"Inception-Restnet-Entropy\"\n","path_save_model = os.path.join(os.getcwd(), \"save_model\", MODEL_NAME)\n","global_value = GlobalValue(image_size=[160,160], batch_size = 96, shuffle_size = 1000, ratio_train = 0.8, ratio_test = 0.1, ratio_valid = 0.1, epochs = 40, small_epochs = 50,\n","                           image_each_class = 15)\n","format_function = FormatFunction(global_value)\n","file_function = FileFunction()"]},{"cell_type":"markdown","source":["##Prepare folder and other thing"],"metadata":{"id":"CNrrqpjynVoz"}},{"cell_type":"code","source":["# Create folder to save model\n","if not os.path.exists(path_save_model):\n","  os.makedirs(path_save_model)\n","\n","#Read label dictionary\n","if READ_RAW_DATA_THEN_SAVE: \n","  label_dict = format_function.get_label_dict(os.path.join(os.getcwd(),\"align_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","  with open(path, 'wb') as file:\n","    pickle.dump(label_dict, file)\n","path = os.path.join(os.getcwd(),\"src\",\"data\",\"label_dict.pkl\")\n","with open(path, 'rb') as f:\n","  label_dict = pickle.load(f)\n","\n","#Save data path to file to read faster\n","if READ_RAW_DATA_THEN_SAVE:\n","  path_image_align  = file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"align_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"align_data_path.pkl\")\n","  with open(path, 'wb') as file:\n","      pickle.dump(path_image_align, file)\n","\n","  path_image_mask  = file_function.get_data_path_by_dictionary(os.path.join(os.getcwd(),\"face+mask_image\"))\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"face+mask_data_path.pkl\")\n","  with open(path, 'wb') as file:\n","      pickle.dump(path_image_mask, file)"],"metadata":{"id":"5pAdqjPenT23","executionInfo":{"status":"ok","timestamp":1656282931025,"user_tz":-420,"elapsed":5,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Dz4PftxE6XC"},"source":["## Start train"]},{"cell_type":"markdown","metadata":{"id":"lZpKIQAUTDpm"},"source":["# Train version 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXpeK2-rTN_n","outputId":"c6ca2d39-c560-4af7-aa62-3bff5ff817e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["load  /content/drive/My Drive/Colab Notebooks/FaceMaskRecognize/save_model/Inception-Restnet-Entropy/epoch1\n","--------------------------big epoch 2--------------------------\n","5383/5696 [===========================>..] - ETA: 15:27 - loss: 8.1751 - sparse_categorical_accuracy: 0.0051"]}],"source":["# Create embedding model\n","input_shape = [global_value.IMAGE_SIZE[0], global_value.IMAGE_SIZE[1], 3]\n","face_net_model = call_instance_FaceNet_with_last_isDense(input_shape, len(label_dict))\n","face_net_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n","    )\n","#----choose path to save per epoch\n","actual_epochs = 1\n","for i in range(100):\n","  last_save_path = path_save_model+\"/epoch{}\".format(actual_epochs)\n","  if not os.path.exists(last_save_path):\n","    break\n","  actual_epochs += 1\n","\n","# Load save\n","if (actual_epochs != 1):\n","  load_path = path_save_model+\"/epoch{}\".format(actual_epochs-1)\n","  print(\"load \",load_path)\n","  face_net_model = tf.keras.models.load_model(load_path)\n","\n","\n","\n","# Normal train network\n","for i in range(global_value.EPOCHS):\n","\n","  # Measure time\n","  now = time.time()\n","  # Read data path from file\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"align_data_path.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_align = pickle.load(f)\n","      path_image_align = file_function.get_data_path_with_limit(path_image_align,global_value.IMAGE_EACH_CLASS)\n","  path = os.path.join(os.getcwd(),\"src\",\"data\",\"face+mask_data_path.pkl\")\n","  with open(path, 'rb') as f:\n","      path_image_mask = pickle.load(f)\n","      path_image_mask = file_function.get_data_path_with_limit(path_image_mask,global_value.IMAGE_EACH_CLASS)\n","  # Combine data path\n","  path_image_align.extend(path_image_mask)\n","  random.shuffle(path_image_align)\n","  # Index label\n","  label_index =list()\n","  for path in path_image_align:\n","    label = path.split(\"/\")[-2]\n","    label = label_dict[label]\n","    label_index.append(label)\n","  path_dataset = tf.data.Dataset.from_tensor_slices(path_image_align)\n","  label_dataset = tf.data.Dataset.from_tensor_slices(label_index)\n","  origin_dataset = tf.data.Dataset.zip((path_dataset, label_dataset))\n","  # Repeat data\n","  double_data_set  = origin_dataset.shuffle(global_value.SHUFFLE_SIZE).repeat(2)\n","  # Split train, test datase\n","  train_dataset, test_dataset,_ = format_function.get_dataset_partition(double_data_set, 0.9,0.1,0)\n","  # read data from path\n","  train_dataset = train_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","  # data_set = data_set.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","  # augmentation data(flip, rotate,...)\n","  train_dataset = train_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  test_dataset = test_dataset.map(format_function.augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","  # batch data\n","  train_dataset = train_dataset.batch(global_value.BATCH_SIZE)\n","  test_dataset = test_dataset.batch(global_value.BATCH_SIZE)\n","  # Set cache and prefetch to improve performance\n","  train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  test_dataset = test_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n","  print(\"--------------------------big epoch {}--------------------------\".format(actual_epochs))\n","  history = face_net_model.fit(\n","      train_dataset,\n","      epochs = 1,\n","      validation_data = test_dataset\n","  )\n","  face_net_model.save(path_save_model+\"/epoch{}\".format(actual_epochs))\n","  with open(\"src/log/log_{}.txt\".format(MODEL_NAME), \"a\") as file_object:\n","    file_object.write(\"\\n\")\n","    file_object.write(\"epoch {}, loss {}, accuracy {}, loss_valid {}, accuracy_valid {}, time {}\".format(actual_epochs, history.history['loss'], history.history['sparse_categorical_accuracy'], history.history['val_loss'],history.history['val_sparse_categorical_accuracy'], time.time() - now))\n","  actual_epochs += 1\n"]},{"cell_type":"markdown","metadata":{"id":"77wRLLpnwljL"},"source":["## test embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaizwhSWwm9D"},"outputs":[],"source":["# face_net_model = tf.keras.models.load_model(\"save_model/align_image_origin36\")\n","# classify = Classify(face_net_model, format_function)\n","# database_embedding = classify.embedding_all_data_by_directory(os.path.join(os.getcwd(),\"dataset\",\"lfw\"))\n","# classify.save_embedding_to_file(database_embedding, os.path.join(os.getcwd(),\"encodings\",\"encode_lfw_epoch36.pkl\"))\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/lfw/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","\n","# # Accuracy\n","# print(classify.evaluate(test_dataset, database_embedding))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lT1WdCieksnL"},"outputs":[],"source":["# # Load network\n","# face_net_model = tf.keras.models.load_model(\"save_model/face_recognize_entropy47\")\n","# face_net_model =  convert_train_model_to_embedding(face_net_model)\n","# #Preprocess data\n","# test_dataset = tf.data.Dataset.list_files(\"dataset/10_person/*/*\",shuffle=False)\n","# test_dataset = test_dataset.map(format_function.get_label_as_number, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.map(format_function.process_image, num_parallel_calls=tf.data.AUTOTUNE)\n","# test_dataset = test_dataset.filter(lambda image, label: tf.math.not_equal(tf.size(image), 0))\n","# test_dataset = test_dataset.batch(20)\n","# # Evaluate the network\n","# results = face_net_model.predict(test_dataset)\n","\n","# # Save test embeddings for visualization in projector\n","# np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n","\n","# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n","# for img, labels in tfds.as_numpy(test_dataset):\n","#     [out_m.write(str(x) + \"\\n\") for x in labels]\n","# out_m.close()\n","\n","\n","# try:\n","#   from google.colab import files\n","#   files.download('vecs.tsv')\n","#   files.download('meta.tsv')\n","# except:\n","#   pass"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}