{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# AUTO click\n","from pynput.mouse import Controller,Button\n","import time\n","\n","mouse = Controller()\n","\n","while True:\n","    mouse.click(Button.left,1)\n","    print('clicked')\n","    time.sleep(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"elapsed":22,"status":"error","timestamp":1649863544435,"user":{"displayName":"Vũ Đức Lâm Nguyễn","userId":"05507541945691209538"},"user_tz":-420},"id":"BphTVyD4XDAQ","outputId":"4868cd13-b8dc-43e0-d29c-7957debac95e"},"outputs":[],"source":["import cv2,dlib, random,os, csv, time\n","import numpy as np\n","from wear_mask.FacialMaskDataSet import FacialMaskDataSet\n","from wear_mask import MTCNN\n","from tool.FileFunction import FileFunction\n","# jupyter notebook   --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888   --NotebookApp.port_retries=0"]},{"cell_type":"markdown","metadata":{"id":"X9mVP8m9XDAQ"},"source":["# Demo"]},{"cell_type":"markdown","metadata":{"id":"JArtr_K-XDAS"},"source":["## Demo wear mask camera"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4CP2f4bXDAS"},"outputs":[],"source":["facial_mask_dataset = FacialMaskDataSet()\n","file_function =  FileFunction()\n","#----initialization of MTCNN model\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(os.path.join(os.getcwd(),'./models/shape_predictor_68_face_landmarks.dat'))\n","# Read mask pictures\n","maskImagePaths = file_function.getPath(os.path.join(os.getcwd(),\"mask_image\"))\n","numberOfMask = len(maskImagePaths)\n","if numberOfMask <=0:\n","    print(\"there are no mask in \")\n","offsetRandomMask = random.randint(0, numberOfMask - 1)\n","# Open video\n","cap = cv2.VideoCapture(0)\n","ret, frame = cap.read()\n","timer = time.time()\n","while(True):\n","            if (time.time() - timer) >= 2:\n","                print (time.time()-timer)\n","                timer = time.time()\n","                offsetRandomMask = random.randint(0, numberOfMask - 1)\n","            # capture frame by frame\n","            ret, frame = cap.read()\n","            xMin, xMax, yMin, yMax, size, landmarks =facial_mask_dataset.findMouthCoordinate(frame,detector,predictor)\n","            if size is not None:\n","                # If can find all land mark use Homography to overlay mask\n","                landmarks = np.array([[point.x,point.y] for point in landmarks.parts()])\n","                if (len(landmarks) != 0) and (landmarks is not None) and (landmarks > 0).all():\n","                    pathRandomMask = maskImagePaths[offsetRandomMask]\n","                    imageRandomMask = cv2.imread(pathRandomMask, cv2.IMREAD_UNCHANGED)\n","                    coordinatePointsFace = [[point[0], point[1]] for point in landmarks[1:16:1]]\n","                    coordinatePointsFace.append([landmarks[29][0],landmarks[29][1]])\n","                    nameMask = pathRandomMask.split(\"\\\\\")[-1].split(\".\")[0]\n","                    pathAnnotation = os.path.join(os.path.join(os.getcwd(), \"mask_annotation\"),nameMask+\".csv\")\n","                    with open(pathAnnotation) as annotationFile:\n","                        csvReader = csv.reader(annotationFile)\n","                        coordinatePointsMask = []\n","                        for row in csvReader:\n","                            try:\n","                                coordinatePointsMask.append([float(row[1]), float(row[2])])\n","                            except ValueError:\n","                                continue\n","                    coordinatePointsFace = np.array(coordinatePointsFace, dtype = np.float)\n","                    coordinatePointsMask = np.array(coordinatePointsMask, dtype=np.float)\n","                    frame = facial_mask_dataset.attachMaskToFaceHomoGraphy(frame, imageRandomMask, coordinatePointsMask, coordinatePointsFace )\n","            cv2.imshow(\"frame\", frame)\n","            if(cv2.waitKey(1) == ord(\"q\")):\n","                break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{},"source":["# Face recognize"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from train.FaceNet import FaceNetModel,call_instance_FaceNet_with_custom, call_instance_FaceNet_without_custom, call_instance_FaceNet_with_last_isDense,convert_train_model_to_embedding\n","from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","from train.Classify import Classify\n","from tool.FormatFunction import FormatFunction\n","from tool.FileFunction import FileFunction\n","from tool.GlobalValue import GlobalValue\n","\n","\n","\n","global_value = GlobalValue(image_size=[110,110], batch_size = 512, shuffle_size = 1000, ratio_train = 0.8, ratio_test = 0.1, ratio_valid = 0.1, epochs = 40, small_epochs = 50,\n","                           image_each_class = 15)\n","format_function = FormatFunction(global_value)\n","model_path = os.path.join(os.getcwd(),\"\")\n","reload_model  = call_instance_FaceNet_with_last_isDense(global_value.IMAGE_SIZE,10575)\n","reload_model.load_weights(model_path)\n","embedding_model = convert_train_model_to_embedding(reload_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","vector = [1,2,3]\n","vector = vector/np.linalg.norm(vector)\n","print(vector)\n","\n","print(np.linalg.norm(vector))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","print(torch.cuda.get_device_name(0))\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Exception encountered when calling layer \"arc_face_9\" (type ArcFace).\n\nDimensions must be equal, but are 512 and 10 for '{{node arc_face_9/matmul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](arc_face_9/l2_normalize, arc_face_9/l2_normalize_1)' with input shapes: [?,512], [10,512].\n\nCall arguments received by layer \"arc_face_9\" (type ArcFace):\n  • inputs=['tf.Tensor(shape=(None, 512), dtype=float32)', 'tf.Tensor(shape=(None, 10), dtype=float32)']","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mg:\\My Drive\\Colab Notebooks\\FaceMaskRecognize\\Demo.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m x \u001b[39m=\u001b[39m Dense(\u001b[39m512\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_normal\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m x \u001b[39m=\u001b[39m BatchNormalization()(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m output \u001b[39m=\u001b[39m ArcFace(n_classes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)([x, label])\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel([\u001b[39minput\u001b[39m, label], output)\n","File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n","\u001b[1;32mg:\\My Drive\\Colab Notebooks\\FaceMaskRecognize\\Demo.ipynb Cell 10\u001b[0m in \u001b[0;36mArcFace.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m W \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39ml2_normalize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# dot product\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m logits \u001b[39m=\u001b[39m x \u001b[39m@\u001b[39;49m W\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# add margin\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# clip logits to prevent zero division when backward\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/FaceMaskRecognize/Demo.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m theta \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39macos(K\u001b[39m.\u001b[39mclip(logits, \u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m+\u001b[39m K\u001b[39m.\u001b[39mepsilon(), \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m K\u001b[39m.\u001b[39mepsilon()))\n","\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"arc_face_9\" (type ArcFace).\n\nDimensions must be equal, but are 512 and 10 for '{{node arc_face_9/matmul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](arc_face_9/l2_normalize, arc_face_9/l2_normalize_1)' with input shapes: [?,512], [10,512].\n\nCall arguments received by layer \"arc_face_9\" (type ArcFace):\n  • inputs=['tf.Tensor(shape=(None, 512), dtype=float32)', 'tf.Tensor(shape=(None, 10), dtype=float32)']"]}],"source":["from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Layer, Input,  MaxPooling2D, Flatten, Dense,\\\n","    \t\t\t\t\t\tDropout, BatchNormalization, Conv2D\n","from keras import regularizers\n","\n","import tensorflow as tf\n","\n","\n","class ArcFace(Layer):\n","    def __init__(self, n_classes=10, s=30.0, m=0.50, regularizer=None, **kwargs):\n","        super(ArcFace, self).__init__(**kwargs)\n","        self.n_classes = n_classes\n","        self.s = s\n","        self.m = m\n","        self.regularizer = regularizers.get(regularizer)\n","\n","    def build(self, input_shape):\n","        temp = input_shape[0][1:3]\n","        super(ArcFace, self).build(input_shape[0])\n","        temp = input_shape[0][-1]\n","        self.W = self.add_weight(name='W',\n","                                 shape=(self.n_classes, input_shape[0][-1]),\n","                                 initializer='glorot_uniform',\n","                                 trainable=True,\n","                                 regularizer=self.regularizer)\n","\n","    @tf.function\n","    def call(self, inputs):\n","        x, y = inputs\n","        c = K.shape(x)[-1]\n","        # normalize feature\n","        x = tf.nn.l2_normalize(x, axis=1)\n","        # normalize weights\n","        W = tf.nn.l2_normalize(self.W, axis=0)\n","        # dot product\n","        logits = x @ W\n","        # add margin\n","        # clip logits to prevent zero division when backward\n","        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n","        target_logits = tf.cos(theta + self.m)\n","        # sin = tf.sqrt(1 - logits**2)\n","        # cos_m = tf.cos(logits)\n","        # sin_m = tf.sin(logits)\n","        # target_logits = logits * cos_m - sin * sin_m\n","        #\n","        logits = logits * (1 - y) + target_logits * y\n","        # feature re-scale\n","        logits *= self.s\n","        out = tf.nn.softmax(logits)\n","\n","        return out\n","\n","    def compute_output_shape(self, input_shape):\n","        return (None, self.n_classes)\n","\n","tf.config.run_functions_eagerly(True)\n","input = Input(shape=(28, 28, 1))\n","label = Input(shape=(10,))\n","\n","x = Conv2D(32, kernel_size=(3, 3), activation='relu')(input)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","x = Flatten()(x)\n","x = Dense(512, kernel_initializer='he_normal')(x)\n","x = BatchNormalization()(x)\n","output = ArcFace(n_classes=10)([x, label])\n","\n","model = tf.keras.Model([input, label], output)\n","\n","# model.compile(loss='categorical_crossentropy',\n","#               optimizer=Adam(),\n","#               metrics=['accuracy'])\n","\n","# model.fit([x_train, y_train],\n","#           y_train,\n","#           batch_size=batch_size,\n","#           epochs=epochs,\n","#           verbose=1,\n","#           validation_data=([x_test, y_test], y_test),\n","#           callbacks=[ModelCheckpoint('model.hdf5',\n","#                      verbose=1, save_best_only=True)])\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Demo.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.8.13 ('python38')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"725bcb009e1db82e62e6d35a4d1f684f39d1b4e52d6204abc611d06a7adc7e09"}}},"nbformat":4,"nbformat_minor":0}
